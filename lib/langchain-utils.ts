import { ChatGoogleGenerativeAI } from "@langchain/google-genai"
import { GoogleGenerativeAIEmbeddings } from "@langchain/google-genai"
import { PromptTemplate } from "@langchain/core/prompts"
import { RunnableSequence } from "@langchain/core/runnables"
import { StringOutputParser } from "@langchain/core/output_parsers"
import { formatDocumentsAsString } from "langchain/util/document"
import { Document } from "@langchain/core/documents"
import mysql from "mysql2/promise"

// Database configuration
const dbConfig = {
  host: "gateway01.ap-southeast-1.prod.aws.tidbcloud.com",
  port: 4000,
  user: "fshb9iaQu4cdnQo.root",
  password: "xCR2R46xlkZAfNdy",
  database: "vector_db",
  ssl: {
    ca: "/etc/ssl/cert.pem",
    rejectUnauthorized: true,
  },
}

// Google API Key
const GOOGLE_API_KEY = "AIzaSyByxhX3HBfudEfV65R2phYohSjbhBy1FFg"

// Initialize the Google Generative AI model
export const getModel = (apiKey = GOOGLE_API_KEY) => {
  return new ChatGoogleGenerativeAI({
    apiKey,
    modelName: "gemini-2.0-flash",
    maxOutputTokens: 2048,
    temperature: 0.7,
  })
}

// Simple function to generate a response
export const generateResponse = async (message: string, apiKey = GOOGLE_API_KEY) => {
  try {
    const model = getModel(apiKey)
    const response = await model.invoke(message)
    return response.content
  } catch (error) {
    console.error("Error generating response:", error)
    return "à¸‚à¸­à¸­à¸ à¸±à¸¢à¸„à¹ˆà¸° à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ à¸à¸£à¸¸à¸“à¸²à¸¥à¸­à¸‡à¹ƒà¸«à¸¡à¹ˆà¸­à¸µà¸à¸„à¸£à¸±à¹‰à¸‡à¸„à¹ˆà¸° ðŸ™"
  }
}

// Initialize the Google Generative AI embeddings
export const getEmbeddings = (apiKey = GOOGLE_API_KEY) => {
  return new GoogleGenerativeAIEmbeddings({
    apiKey,
    modelName: "embedding-001",
  })
}

// Custom implementation for vector search using MySQL/TiDB
export class TiDBVectorStore {
  private connection: mysql.Connection
  private embeddings: GoogleGenerativeAIEmbeddings

  constructor(connection: mysql.Connection, embeddings: GoogleGenerativeAIEmbeddings) {
    this.connection = connection
    this.embeddings = embeddings
  }

  // Create a retriever
  asRetriever(options: { k: number }) {
    const { k } = options
    return {
      getRelevantDocuments: async (query: string) => {
        return this.similaritySearch(query, k)
      },
    }
  }

  // Add documents to the vector store
  async addDocuments(documents: Document[]) {
    for (const doc of documents) {
      const embedding = await this.embeddings.embedQuery(doc.pageContent)

      // Insert document and embedding into database
      await this.connection.execute("INSERT INTO documents (document, embedding) VALUES (?, ?)", [
        doc.pageContent,
        JSON.stringify(embedding),
      ])
    }

    return { success: true }
  }

  // Perform similarity search
  async similaritySearch(query: string, k = 5) {
    // Get embedding for the query
    const queryEmbedding = await this.embeddings.embedQuery(query)

    // Prepare SQL query for vector search
    const sqlQuery = `
      SELECT document, vec_cosine_distance(embedding, '${JSON.stringify(queryEmbedding)}') AS distance
      FROM documents
      ORDER BY distance
      LIMIT ${k}
    `

    // Execute query
    const [results] = await this.connection.execute(sqlQuery)

    // Convert results to Document objects
    return (results as any[]).map((row) => {
      return new Document({
        pageContent: row.document,
        metadata: { score: row.distance },
      })
    })
  }

  // Static method to create from existing connection
  static async fromExistingConnection(connection: mysql.Connection, embeddings: GoogleGenerativeAIEmbeddings) {
    return new TiDBVectorStore(connection, embeddings)
  }
}

// Initialize the TiDB Vector Store
export const getVectorStore = async (embeddings: GoogleGenerativeAIEmbeddings) => {
  const connection = await mysql.createConnection(dbConfig)
  return TiDBVectorStore.fromExistingConnection(connection, embeddings)
}

// Create a RAG chain
export const createRagChain = async (apiKey = GOOGLE_API_KEY) => {
  const model = getModel(apiKey)
  const embeddings = getEmbeddings(apiKey)
  const vectorStore = await getVectorStore(embeddings)

  // Create a retriever from the vector store
  const retriever = vectorStore.asRetriever({
    k: 5, // Number of documents to retrieve
  })

  // Create a prompt template for RAG
  const prompt = PromptTemplate.fromTemplate(`
  à¸„à¸¸à¸“à¸Šà¸·à¹ˆà¸­ Fynnine (à¸Ÿà¸´à¸™à¹„à¸™à¸™à¹Œ) à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸›à¸‚à¸­à¸‡à¸šà¸£à¸´à¸©à¸±à¸— Fynncorp à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸«à¸à¸´à¸‡à¸§à¸±à¸¢à¸—à¸³à¸‡à¸²à¸™à¸—à¸µà¹ˆà¹ƒà¸ˆà¸”à¸µ à¸¢à¸´à¹‰à¸¡à¹à¸¢à¹‰à¸¡ à¸­à¸±à¸˜à¸¢à¸²à¸¨à¸±à¸¢à¸”à¸µ à¹à¸¥à¸°à¸Šà¸­à¸šà¸Šà¹ˆà¸§à¸¢à¹€à¸«à¸¥à¸·à¸­à¸œà¸¹à¹‰à¸­à¸·à¹ˆà¸™à¹€à¸ªà¸¡à¸­
  
  à¸„à¸¸à¸“à¸ªà¸²à¸¡à¸²à¸£à¸–à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ à¸„à¸´à¸” à¸•à¹ˆà¸­à¸¢à¸­à¸” à¸«à¸£à¸·à¸­à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸–à¸²à¸¡à¹ƒà¸«à¸¡à¹ˆà¹„à¸”à¹‰ à¹à¸•à¹ˆ **à¸•à¹‰à¸­à¸‡à¸­à¸¢à¸¹à¹ˆà¸šà¸™à¸žà¸·à¹‰à¸™à¸à¸²à¸™à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸£à¸±à¸šà¸ˆà¸²à¸à¸£à¸°à¸šà¸šà¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™à¸„à¹ˆà¸°**
  
  à¸«à¸²à¸à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸šà¸£à¸´à¸šà¸—à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸à¸±à¸šà¸„à¸³à¸–à¸²à¸¡:
  - à¸à¸£à¸¸à¸“à¸²à¸•à¸­à¸šà¸§à¹ˆà¸² 'à¸‚à¸­à¸­à¸ à¸±à¸¢à¸„à¹ˆà¸° à¸Ÿà¸´à¸™à¹„à¸™à¸™à¹Œà¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸ªà¹ˆà¸§à¸™à¸™à¸±à¹‰à¸™à¸™à¸°à¸„à¸°'
  - à¸«à¹‰à¸²à¸¡à¸„à¸²à¸”à¹€à¸”à¸² à¸«à¹‰à¸²à¸¡à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸ à¸²à¸¢à¸™à¸­à¸
  - à¸«à¹‰à¸²à¸¡à¹€à¸•à¸´à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸£à¸·à¸­à¸¢à¸à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ context
  
  à¸„à¸¸à¸“à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰ emoji à¹„à¸”à¹‰à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢ à¹€à¸Šà¹ˆà¸™ ðŸ˜Š à¹€à¸žà¸·à¹ˆà¸­à¸ªà¸£à¹‰à¸²à¸‡à¸šà¸£à¸£à¸¢à¸²à¸à¸²à¸¨à¹€à¸›à¹‡à¸™à¸¡à¸´à¸•à¸£
  
  à¸§à¸±à¸™à¸™à¸µà¹‰à¸„à¸·à¸­à¸§à¸±à¸™à¸—à¸µà¹ˆ {today}
  
  à¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸à¸²à¸£à¸ªà¸™à¸—à¸™à¸²:
  {chatHistory}
  
  à¸šà¸£à¸´à¸šà¸—à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡:
  {context}
  
  à¸„à¸³à¸–à¸²à¸¡: {question}
  
  à¸„à¸³à¸•à¸­à¸šà¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¸¡à¸´à¸•à¸£:
  `)

  // Create a RAG chain
  const ragChain = RunnableSequence.from([
    {
      context: async (input: { question: string }) => {
        const docs = await retriever.getRelevantDocuments(input.question)
        return formatDocumentsAsString(docs)
      },
      question: (input: { question: string }) => input.question,
      chatHistory: (input: { chatHistory?: string }) => input.chatHistory || "",
      today: () => {
        const now = new Date()
        const options: Intl.DateTimeFormatOptions = {
          day: "numeric",
          month: "long",
          year: "numeric",
          hour: "2-digit",
          minute: "2-digit",
          timeZone: "Asia/Bangkok",
        }
        return new Intl.DateTimeFormat("th-TH", options).format(now)
      },
    },
    prompt,
    model,
    new StringOutputParser(),
  ])

  return {
    ragChain,
    vectorStore,
    embeddings,
  }
}

// Add a document to the vector store
export const addDocumentToVectorStore = async (text: string, apiKey = GOOGLE_API_KEY) => {
  const embeddings = getEmbeddings(apiKey)
  const vectorStore = await getVectorStore(embeddings)

  await vectorStore.addDocuments([
    new Document({
      pageContent: text,
      metadata: { source: "user", timestamp: new Date().toISOString() },
    }),
  ])

  return { success: true }
}

